{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "repo_path = '/home/jamshid/codes/social-knowledge-analysis/'\n",
    "sys.path.insert(0,repo_path)\n",
    "from data import readers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/jamshid/codes/Certainty/BioCertainty/BioCertainty-master/data'\n",
    "training_set = data_dir + '/training_set.csv'\n",
    "model_json = data_dir+'/model.json'\n",
    "model_h5 = data_dir+'/model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 6660\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "fin = (codecs.open(training_set, \"r\",  encoding='utf8'))\n",
    "maxlen = 0\n",
    "for line in fin:\n",
    "    sent = (line.strip().replace('\\n', ' '))\n",
    "    sent = [x for x in nltk.word_tokenize(sent) if x not in stopwords]\n",
    "    texts.append(' '.join(sent))\n",
    "    if len(sent) > maxlen:\n",
    "        maxlen = len(sent)\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = maxlen\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(model_json, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(model_h5)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Certainty(sents):\n",
    "\n",
    "    # initial tokenizing the sentences\n",
    "    sents = [np.array(nltk.word_tokenize(s.strip())) for s in sents]\n",
    "    sents = [x[~np.isin(x,stopwords)] for x in sents]\n",
    "    sents = [' '.join(x) for x in sents]\n",
    "\n",
    "    # converting texts to sequences of integers and padding to a fixed-length vector\n",
    "    seqs = tokenizer.texts_to_sequences(sents)\n",
    "    pseqs = pad_sequences(seqs, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    pseqs = tf.convert_to_tensor(pseqs)\n",
    "\n",
    "    # Evaluate model\n",
    "    preds = model.predict_on_batch(pseqs)\n",
    "    classes = np.argmax(preds,axis=1)\n",
    "\n",
    "    return preds, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/home/jamshid/codes/Certainty/'\n",
    "\n",
    "INPUT_FILE = folder+\"Corpus/Complete_statements_training_set__ML_model.csv\"\n",
    "\n",
    "texts = []   # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "fin = codecs.open(INPUT_FILE, \"r\", encoding='utf8')\n",
    "maxlen = 0\n",
    "for line in fin:\n",
    "    sent, certain = line.strip().split(\"\\t\")\n",
    "    sent = [x for x in nltk.word_tokenize(sent) if x not in stopwords]\n",
    "    texts.append(' '.join(sent))\n",
    "    labels.append(certain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.array(texts)\n",
    "labels = np.uint8(np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([Certainty(x)[0][0] for x in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93178893, 0.7976308 , 0.6252354 ])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(labels, preds+1, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Short Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zero-shot** classification can be easily done through `huggingface`'s `pipeline`. The models offered in the pipeline consist of pretrained transformers that could run for particular tasks over a totally test samples coming from totally unseen data sets. Text classification is one example of these tasks, where the pretrained model could be used to infer the class labels of a given text. Most useful feature is that these class labels are an arbitrary set of strings and determined by the user. Hence, we can use such zero-shot classification to measure the uncertainty of any given sequence just by processing the way the language is used in there.\n",
    "\n",
    "Not all transformers are available for zero-shot tasks. The main pretrained models that could be used with this `pipeline` are those with encoders, hence variants of BERT and BART architectures. The way zero-shot classification works is by converting the classification problem into a Next Sentence Prediction (NSP), where the model is to infer whether in a pair of given sentences the second one is a natural continuation of the first one. For any given sequence (sentence), the pipeline model will pair it with the auxiliary sentence `\"This is [LABEL]\"` where `[LABEL]` is one of the classification labels (e.g., `\"certain\"`). The output of the models would be a probability that the input sequence is related to this auxiliary one. The default model in the pipeline for this task is `bart-large-mnli`.\n",
    "\n",
    "Here's more description of the [zero-shot classification pipeline](https://discuss.huggingface.co/t/new-pipeline-for-zero-shot-text-classification/681)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartModel: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/bart-large-mnli were not used when initializing BartForSequenceClassification: ['model.encoder.version', 'model.decoder.version']\n",
      "- This IS expected if you are initializing BartForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BartForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_subuncert(sents):\n",
    "    \n",
    "    labels = [\"certain\", \"uncertain\"]\n",
    "    \n",
    "    R = classifier(sents,\n",
    "                   candidate_labels=labels,\n",
    "                   multi_class=False)\n",
    "    scores = np.array([np.array(x['scores'])[np.array(x['labels'])=='uncertain'][0] for x in R])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv('/home/jamshid/codes/data/SubjectiveCertainty/Sasha/augmented_lit_v1.csv.gz')\n",
    "G = pd.read_csv('/home/jamshid/codes/data/SubjectiveCertainty/Sasha/augmented_gw_v1.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.fillna('',inplace=True)\n",
    "G.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up</th>\n",
       "      <th>dn</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pos</th>\n",
       "      <th>cdf_exp</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sub_uncertainty</th>\n",
       "      <th>zero_shot_su</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>10970099</td>\n",
       "      <td>1</td>\n",
       "      <td>0.527944</td>\n",
       "      <td>Multiple forms of alpha2-macroglobulin from a ...</td>\n",
       "      <td>Unlike mammals, bony fish possess multiple gen...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>213</td>\n",
       "      <td>1711509</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296639</td>\n",
       "      <td>The effect of alpha 2 macroglobulin-proteinase...</td>\n",
       "      <td>Alpha-2-Macroglobulin (alpha 2M) is a major pl...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>213</td>\n",
       "      <td>18579803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296639</td>\n",
       "      <td>Copper is taken up efficiently from albumin an...</td>\n",
       "      <td>Ionic copper entering blood plasma binds tight...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>12443958</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528730</td>\n",
       "      <td>The association between extrinsic activated pr...</td>\n",
       "      <td>Recently, discussions have focused on the ques...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>18206217</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528730</td>\n",
       "      <td>Treatment of endothelium with the chemotherapy...</td>\n",
       "      <td>Activated protein C (APC) is well-established ...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   up   dn      pmid  pos   cdf_exp  \\\n",
       "0   2  109  10970099    1  0.527944   \n",
       "1   2  213   1711509    1  0.296639   \n",
       "2   2  213  18579803    1  0.296639   \n",
       "3   2  324  12443958    1  0.528730   \n",
       "4   2  324  18206217    1  0.528730   \n",
       "\n",
       "                                               title  \\\n",
       "0  Multiple forms of alpha2-macroglobulin from a ...   \n",
       "1  The effect of alpha 2 macroglobulin-proteinase...   \n",
       "2  Copper is taken up efficiently from albumin an...   \n",
       "3  The association between extrinsic activated pr...   \n",
       "4  Treatment of endothelium with the chemotherapy...   \n",
       "\n",
       "                                            abstract  sub_uncertainty  \\\n",
       "0  Unlike mammals, bony fish possess multiple gen...         0.428571   \n",
       "1  Alpha-2-Macroglobulin (alpha 2M) is a major pl...         0.181818   \n",
       "2  Ionic copper entering blood plasma binds tight...         0.200000   \n",
       "3  Recently, discussions have focused on the ques...         0.083333   \n",
       "4  Activated protein C (APC) is well-established ...         0.062500   \n",
       "\n",
       "   zero_shot_su  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D['zero_shot_su']=0\n",
    "G['zero_shot_su']=0\n",
    "D.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mat2vec.processing import process\n",
    "    pr = process.MaterialsTextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15494/15494 [04:01<00:00, 70.81it/s]"
     ]
    }
   ],
   "source": [
    "lb = 0\n",
    "\n",
    "tqdm_list = tqdm(range(len(G)), position=0, leave=True)\n",
    "while lb<=len(G):\n",
    "    \n",
    "    abst = [' '.join(pr.process(x)[0]) for x in G.iloc[lb:lb+500,].abstract if len(x)>0]\n",
    "    sents = sum([list(filter(None, x.strip().split('.'))) for x in abst], [])\n",
    "    nsents = [len(list(filter(None, x.strip().split('.')))) for x in abst]\n",
    "    pmids = [G.iloc[lb+i].pmid for i,x in enumerate(G.iloc[lb:lb+500,].abstract) if len(x)>0]\n",
    "    \n",
    "    unc = Certainty(sents)[1]\n",
    "    \n",
    "    for i in range(len(nsents)):\n",
    "        _lb = int(np.sum(nsents[:i]))\n",
    "        _ub = int(np.sum(nsents[:i+1]))\n",
    "        avg_unc = np.mean(unc[_lb:_ub])\n",
    "        G.loc[G['pmid']==pmids[i],['sub_uncertainty']]= avg_unc\n",
    "    \n",
    "    lb += 500\n",
    "    tqdm_list.update(min(500,len(G)-lb+500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "abst = [' '.join(pr.process(x)[0]) for x in G.iloc[:2].abstract if len(x)>0]\n",
    "sents = sum([list(filter(None, x.strip().split('.'))) for x in abst], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.to_csv('/home/jamshid/codes/data/SubjectiveCertainty/Sasha/augmented_gw_v1.csv.gz', \n",
    "         index=False,\n",
    "         compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up</th>\n",
       "      <th>dn</th>\n",
       "      <th>pmid</th>\n",
       "      <th>pos</th>\n",
       "      <th>cdf_exp</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>sub_uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>3141384</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490085</td>\n",
       "      <td>Alteration of the carboxyl-terminal domain of ...</td>\n",
       "      <td>The ada gene of Escherichia coli K-12 encodes ...</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1924363</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490085</td>\n",
       "      <td>A region of the Ada DNA-repair protein require...</td>\n",
       "      <td>The adaptive response of Escherichia coli prot...</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>7937881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490085</td>\n",
       "      <td>The Ada protein acts as both a positive and a ...</td>\n",
       "      <td>The adaptive response of Escherichia coli prot...</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>12013490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490085</td>\n",
       "      <td>Possible role of adenosine deaminase in vaso-o...</td>\n",
       "      <td>To describe several emerging concepts regardin...</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>8986139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490085</td>\n",
       "      <td>Effect of deoxycoformycin and Val-boroPro on t...</td>\n",
       "      <td>CD26 and ecto-adenosine deaminase (ADA) are fo...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    up   dn      pmid  pos   cdf_exp  \\\n",
       "0  100  100   3141384    1  0.490085   \n",
       "1  100  100   1924363    1  0.490085   \n",
       "2  100  100   7937881    1  0.490085   \n",
       "3  100  100  12013490    1  0.490085   \n",
       "4  100  100   8986139    0  0.490085   \n",
       "\n",
       "                                               title  \\\n",
       "0  Alteration of the carboxyl-terminal domain of ...   \n",
       "1  A region of the Ada DNA-repair protein require...   \n",
       "2  The Ada protein acts as both a positive and a ...   \n",
       "3  Possible role of adenosine deaminase in vaso-o...   \n",
       "4  Effect of deoxycoformycin and Val-boroPro on t...   \n",
       "\n",
       "                                            abstract  sub_uncertainty  \n",
       "0  The ada gene of Escherichia coli K-12 encodes ...         0.111111  \n",
       "1  The adaptive response of Escherichia coli prot...         0.125000  \n",
       "2  The adaptive response of Escherichia coli prot...         0.333333  \n",
       "3  To describe several emerging concepts regardin...         0.571429  \n",
       "4  CD26 and ecto-adenosine deaminase (ADA) are fo...         0.166667  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = pd.read_csv('/home/jamshid/codes/data/SubjectiveCertainty/Sasha/augmented_gw_v1.csv.gz')\n",
    "D = pd.read_csv('/home/jamshid/codes/data/SubjectiveCertainty/Sasha/augmented_lit_v1.csv.gz')\n",
    "G.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamshid/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jamshid/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gsu = G[~G.pmid.duplicated()].sub_uncertainty\n",
    "dsu = D[~D.pmid.duplicated()].sub_uncertainty\n",
    "plt.hist(gsu, 40, normed=True);\n",
    "plt.hist(dsu, 40, alpha=.5, normed=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = classifier(\n",
    "    [\"This course could be about the Transformers library.\", \n",
    "     \"I suspect that it is this way.\", \n",
    "     \"I have no doubt that you are true\",\n",
    "     \"these data suggest that GM may thus provide a beneficial effect which improves the microcirculatory environment and prevents tissue damage by inhibiting the activation of the vascular EC themselves\"],\n",
    "    candidate_labels=[\"certain\", \"uncertain\"],\n",
    "    multi_class=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained SciBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pd.read_csv('/home/jamshid/codes/data/SubjectiveCertainty/augmented_lit_v1.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[~D['abstract'].isnull()][['pmid','abstract']].to_csv('/home/jamshid/codes/abstract-parser/ArgZoneTaggerV3.0/lit_v1.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the abstracts are saved in a tab-separated file format, we can run [Prabhakaran's](https://nlp.stanford.edu/pubs/prabhakaran2016rhetoricalroles.pdf) method on the abstracts to extract the findings stated in them (sentences classified as \"RESULT\"). We run this method in the bash by executing the following command:\n",
    "```\n",
    "java -jar ArgZoneTagger.jar config/Runner.properties lit_v1.tsv parse_lit_v1.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_csv('/home/jamshid/codes/abstract-parser/ArgZoneTaggerV3.0/parsed_lit_v1.tsv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 504218/504218 [00:42<00:00, 11780.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# collecting out all the extracted finding sentences into a dictionary with keys as the distinct PMIDs\n",
    "# and values as the extracted findings of them\n",
    "results = {}\n",
    "tqdm_list = tqdm(range(len(A)), position=0, leave=True)\n",
    "for i in tqdm_list:\n",
    "    row = A.iloc[i]\n",
    "    rtype = row[0]\n",
    "    if rtype=='ABSTRACT':\n",
    "        # if we are not at the first iteration, the results should be updated\n",
    "        if i>0:\n",
    "            results[pmid] = pmid_results\n",
    "        pmid = row[1]\n",
    "        pmid_results = []\n",
    "    else:\n",
    "        if rtype=='RESULT':\n",
    "            pmid_results += [row[1]]\n",
    "    \n",
    "    # in the last iteration, update the results for the last PMID\n",
    "    if i==len(A)-1:\n",
    "        results[pmid] = pmid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.insert(7,'findings',np.nan)\n",
    "\n",
    "for pmid in results:\n",
    "    D.loc[D.pmid==int(pmid), 'findings'] = ' '.join(results[pmid][:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the pretrained ScieBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/jamshid/codes/Certainty/certainty-estimator/'\n",
    "sys.path.insert(0,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from certainty_estimator.predict_certainty import CertaintyEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jamshid/codes/Certainty/certainty-estimator/')\n",
    "estimator = CertaintyEstimator('sentence-level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model = estimator.model.to('cuda:0')\n",
    "estimator.cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['scibert_min'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45110/45110 [10:35<00:00, 70.96it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm_list = tqdm(results.items(), position=0, leave=True)\n",
    "for pmid, findings in tqdm_list:\n",
    "    if len(findings)==0:\n",
    "        continue\n",
    "    certs = estimator.predict(findings[:-1])\n",
    "    D.loc[D.pmid==int(pmid), 'scibert_mean'] = np.mean(certs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scibert_mean</th>\n",
       "      <th>scibert_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.922029</td>\n",
       "      <td>4.474798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.944395</td>\n",
       "      <td>4.614956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.150705</td>\n",
       "      <td>4.995833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.105231</td>\n",
       "      <td>4.906292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.026688</td>\n",
       "      <td>4.926039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50472</th>\n",
       "      <td>4.924084</td>\n",
       "      <td>4.273334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50473</th>\n",
       "      <td>4.974516</td>\n",
       "      <td>4.874775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50474</th>\n",
       "      <td>5.025101</td>\n",
       "      <td>5.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50475</th>\n",
       "      <td>5.025627</td>\n",
       "      <td>4.978360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50476</th>\n",
       "      <td>5.024417</td>\n",
       "      <td>4.885170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50477 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       scibert_mean  scibert_min\n",
       "0          4.922029     4.474798\n",
       "1          4.944395     4.614956\n",
       "2          5.150705     4.995833\n",
       "3          5.105231     4.906292\n",
       "4          5.026688     4.926039\n",
       "...             ...          ...\n",
       "50472      4.924084     4.273334\n",
       "50473      4.974516     4.874775\n",
       "50474      5.025101     5.000871\n",
       "50475      5.025627     4.978360\n",
       "50476      5.024417     4.885170\n",
       "\n",
       "[50477 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D[['scibert_mean','scibert_min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
